import os
import time
import streamlit as st
import matplotlib.pyplot as plt
from concurrent.futures import ThreadPoolExecutor, as_completed
import pandas as pd

from common.utils import safe_filename, get_cached_data
from holding_tracker import (
    generate_holding_matrix,
    display_holding_heatmap,
    download_holding_csv,
)
from common.performance_summary import summarize_results
from tickers_loader import get_all_tickers
from common.backtest_utils import log_progress
import matplotlib.ticker as mticker


# ============================================================
# å…±é€šé€²æ—ãƒ­ã‚°é–¢æ•°ï¼ˆSystem1 å½¢å¼ï¼‰
# ============================================================
def log_with_progress(
    i,
    total,
    start_time,
    prefix="å‡¦ç†",
    batch=50,
    log_area=None,
    progress_bar=None,
    extra_msg=None,
):
    """System1å½¢å¼ã®é€²æ—ãƒ­ã‚°ï¼‹é€²æ—ãƒãƒ¼ã‚’è¡¨ç¤º"""
    if i % batch == 0 or i == total:
        elapsed = time.time() - start_time
        remain = (elapsed / i) * (total - i) if i > 0 else 0
        msg = (
            f"{prefix}: {i}/{total} ä»¶ å®Œäº† "
            f"| çµŒé: {int(elapsed // 60)}åˆ†{int(elapsed % 60)}ç§’ "
            f"/ æ®‹ã‚Š: ç´„ {int(remain // 60)}åˆ†{int(remain % 60)}ç§’"
        )
        if extra_msg:
            msg += f"\n{extra_msg}"
        if log_area:
            log_area.text(msg)
        if progress_bar:
            progress_bar.progress(i / total)


# ============================================================
# ãƒ‡ãƒ¼ã‚¿å–å¾—ï¼ˆå…±é€šï¼‰
# ============================================================
def load_symbol(symbol, cache_dir="data_cache"):
    path = os.path.join(cache_dir, f"{safe_filename(symbol)}.csv")
    if not os.path.exists(path):
        return symbol, None
    return symbol, get_cached_data(symbol)


def fetch_data(symbols, max_workers=8):
    data_dict = {}
    total = len(symbols)
    st.info(f"ğŸ“„ ãƒ‡ãƒ¼ã‚¿å–å¾—é–‹å§‹ | {total} éŠ˜æŸ„ã‚’å‡¦ç†ä¸­...")
    progress_bar = st.progress(0)
    log_area = st.empty()
    buffer, start_time = [], time.time()

    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        futures = {executor.submit(load_symbol, sym): sym for sym in symbols}
        for i, future in enumerate(as_completed(futures), 1):
            sym, df = future.result()
            if df is not None and not df.empty:
                data_dict[sym] = df
                buffer.append(sym)

            # --- System1å½¢å¼ã®é€²æ—ãƒ­ã‚° ---
            log_with_progress(
                i,
                total,
                start_time,
                prefix="ğŸ“„ ãƒ‡ãƒ¼ã‚¿å–å¾—",
                batch=50,
                log_area=log_area,
                progress_bar=progress_bar,
                extra_msg=f"éŠ˜æŸ„: {', '.join(buffer)}" if buffer else None,
            )
            buffer.clear()

    progress_bar.empty()
    return data_dict


# ============================================================
# ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆã‚¢ãƒ—ãƒªå…±é€šæœ¬ä½“
# ============================================================
def run_backtest_app(
    strategy, system_name="SystemX", system_title=None, limit_symbols=500, **kwargs
):
    # --- ã‚¿ã‚¤ãƒˆãƒ« ---
    if system_title:
        st.title(system_title)
    else:
        st.title(f"{system_name} ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆ")

    # --- ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒªã‚¢ ---
    if st.button("âš ï¸ Streamlitã‚­ãƒ£ãƒƒã‚·ãƒ¥å…¨ã‚¯ãƒªã‚¢"):
        st.cache_data.clear()
        st.success("Streamlit cache cleared.")

    # --- ãƒ†ã‚£ãƒƒã‚«ãƒ¼é¸æŠ ---
    use_auto = st.checkbox("è‡ªå‹•ãƒ†ã‚£ãƒƒã‚«ãƒ¼å–å¾—ï¼ˆå…¨éŠ˜æŸ„ï¼‰", value=True)
    capital = st.number_input("ç·è³‡é‡‘ï¼ˆUSDï¼‰", min_value=1000, value=1000, step=100)

    all_tickers = get_all_tickers()
    max_allowed = len(all_tickers)
    default_value = min(10, max_allowed)

    # ğŸ”½ å–å¾—éŠ˜æŸ„æ•°æŒ‡å®šUI
    limit_symbols = st.number_input(
        "å–å¾—éŠ˜æŸ„æ•°ï¼ˆä¸Šé™ï¼‰",
        min_value=10,
        max_value=max_allowed,
        value=default_value,
        step=100,
        key=f"{system_name}_limit",
    )

    # ğŸ”½ å…¨éŠ˜æŸ„ã‚’å¯¾è±¡ã«ã™ã‚‹ã‚ªãƒ—ã‚·ãƒ§ãƒ³
    if st.checkbox("å…¨éŠ˜æŸ„ã‚’å¯¾è±¡ã«å®Ÿæ–½", key=f"{system_name}_all"):
        limit_symbols = max_allowed

    symbols_input = None
    if not use_auto:
        symbols_input = st.text_input(
            "ãƒ†ã‚£ãƒƒã‚«ãƒ¼ã‚’ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šã§å…¥åŠ›",
            "AAPL,MSFT,TSLA,NVDA,META",
            key=f"{system_name}_symbols_main",
        )

    # --- å®Ÿè¡Œãƒœã‚¿ãƒ³ ---
    if st.button("ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ", key=f"{system_name}_run"):

        # --- symbols ã‚’æ±ºå®š ---
        if system_name == "System7":
            # System7ã¯SPYã®ã¿ã‚’å¯¾è±¡
            symbols = ["SPY"]

        else:
            if use_auto:
                symbols = all_tickers[:limit_symbols]
            else:
                if not symbols_input:
                    st.error("éŠ˜æŸ„ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
                    return
                symbols = [s.strip().upper() for s in symbols_input.split(",")]

            # System1ã¯SPYã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ç”¨ã«è¿½åŠ ï¼ˆå¯¾è±¡éŠ˜æŸ„ã«ã¯ã—ãªã„ï¼‰
            if system_name == "System1" and "SPY" not in symbols:
                # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼å°‚ç”¨ãªã®ã§åˆ¥é€”èª­ã¿è¾¼ã‚€ã€symbolsã«ã¯è¿½åŠ ã—ãªã„
                spy_df = get_cached_data("SPY")
                if spy_df is None or spy_df.empty:
                    st.error(
                        "SPYãƒ‡ãƒ¼ã‚¿ãŒå–å¾—ã§ãã¾ã›ã‚“ã€‚ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’æ›´æ–°ã—ã¦ãã ã•ã„ã€‚"
                    )
                    return

        # --- ãƒ‡ãƒ¼ã‚¿å–å¾— ---
        data_dict = fetch_data(symbols)
        if not data_dict:
            st.error("æœ‰åŠ¹ãªãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
            return

        # --- ã‚¤ãƒ³ã‚¸ã‚±ãƒ¼ã‚¿ãƒ¼è¨ˆç®— ---
        st.info("ğŸ“Š ã‚¤ãƒ³ã‚¸ã‚±ãƒ¼ã‚¿ãƒ¼è¨ˆç®—ä¸­...")
        ind_progress = st.progress(0)
        ind_log = st.empty()
        start_time = time.time()

        prepared_dict = strategy.prepare_data(
            data_dict,
            progress_callback=lambda done, total: log_with_progress(
                done,
                total,
                start_time,
                prefix="ğŸ“Š æŒ‡æ¨™è¨ˆç®—",
                batch=50,
                log_area=ind_log,
                progress_bar=ind_progress,
            ),
            **kwargs,
        )
        ind_progress.empty()

        # --- å€™è£œæŠ½å‡º ---
        st.info("ğŸ“Š ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—æŠ½å‡ºä¸­...")
        cand_progress = st.progress(0)
        cand_log = st.empty()
        start_time = time.time()

        if system_name == "System1":
            # SPYãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã‚’ä½¿ã£ã¦å€™è£œæŠ½å‡º
            candidates_by_date, merged_df = strategy.generate_candidates(
                prepared_dict,
                spy_df,  # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼å°‚ç”¨
                progress_callback=lambda done, total: log_with_progress(
                    done,
                    total,
                    start_time,
                    prefix="ğŸ“Š å€™è£œæŠ½å‡º",
                    batch=10,
                    log_area=cand_log,
                    progress_bar=cand_progress,
                ),
                **kwargs,
            )

        elif system_name == "System7":
            # SPYã®ã¿ãŒå¯¾è±¡ãªã®ã§prepared_dictã«SPYã ã‘ãŒå…¥ã£ã¦ã„ã‚‹æƒ³å®š
            candidates_by_date = strategy.generate_candidates(
                prepared_dict,
                progress_callback=lambda done, total: log_with_progress(
                    done,
                    total,
                    start_time,
                    prefix="ğŸ“Š å€™è£œæŠ½å‡º",
                    batch=10,
                    log_area=cand_log,
                    progress_bar=cand_progress,
                ),
                **kwargs,
            )

        else:
            # System2ã€œ6ã¯SPYã‚’ä½¿ã‚ãšé€šå¸¸é€šã‚Š
            candidates_by_date, merged_df = strategy.generate_candidates(
                prepared_dict,
                progress_callback=lambda done, total: log_with_progress(
                    done,
                    total,
                    start_time,
                    prefix="ğŸ“Š å€™è£œæŠ½å‡º",
                    batch=10,
                    log_area=cand_log,
                    progress_bar=cand_progress,
                ),
                **kwargs,
            )
        cand_progress.empty()

        # --- ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆ ---
        st.info("ğŸ’¹ ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆå®Ÿè¡Œä¸­...")
        bt_progress = st.progress(0)
        bt_log = st.empty()
        start_time = time.time()

        results_df = strategy.run_backtest(
            prepared_dict,
            candidates_by_date,
            capital,
            on_progress=lambda i, total, start: log_with_progress(
                i,
                total,
                start,
                prefix="ğŸ’¹ ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆ",
                batch=50,
                log_area=bt_log,
                progress_bar=bt_progress,
            ),
            **kwargs,
        )
        bt_progress.empty()

        if results_df.empty:
            st.info("ãƒˆãƒ¬ãƒ¼ãƒ‰ã¯ç™ºç”Ÿã—ã¾ã›ã‚“ã§ã—ãŸã€‚")
            return

        st.success("âœ… ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆå®Œäº†")

        # --- çµæœè¡¨ç¤º ---
        st.subheader("ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆçµæœ")
        st.dataframe(results_df)

        summary, results_df = summarize_results(results_df, capital)
        col1, col2, col3, col4 = st.columns(4)
        col1.metric("ãƒˆãƒ¬ãƒ¼ãƒ‰å›æ•°", summary["trades"])
        col2.metric("æœ€çµ‚æç›Š (USD)", f"{summary['total_return']:.2f}")
        col3.metric("å‹ç‡ (%)", f"{summary['win_rate']:.2f}")
        col4.metric("æœ€å¤§ãƒ‰ãƒ­ãƒ¼ãƒ€ã‚¦ãƒ³ (USD)", f"{summary['max_dd']:.2f}")

        # --- æç›Šã‚°ãƒ©ãƒ• ---
        st.subheader("ğŸ“ˆ ç´¯ç©æç›Š")
        plt.figure(figsize=(10, 4))
        plt.plot(
            results_df["exit_date"],
            results_df["cumulative_pnl"],
            label="Cumulative PnL",
        )
        plt.xlabel("æ—¥ä»˜")
        plt.ylabel("æç›Š (USD)")
        plt.title("ç´¯ç©æç›Š")
        plt.legend()
        st.pyplot(plt)

        # --- ã‚µãƒãƒªãƒ¼ ---
        st.subheader("ğŸ“… å¹´æ¬¡ã‚µãƒãƒªãƒ¼")
        st.dataframe(
            results_df.groupby(results_df["exit_date"].dt.to_period("Y"))["pnl"]
            .sum()
            .reset_index()
        )

        st.subheader("ğŸ“† æœˆæ¬¡ã‚µãƒãƒªãƒ¼")
        st.dataframe(
            results_df.groupby(results_df["exit_date"].dt.to_period("M"))["pnl"]
            .sum()
            .reset_index()
        )

        st.subheader("ğŸ“Š æ—¥åˆ¥ä¿æœ‰éŠ˜æŸ„ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—")
        # æ—¥åˆ¥ä¿æœ‰éŠ˜æŸ„ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ç”Ÿæˆã®é€²æ—è¡¨ç¤º
        st.info("ğŸ“Š æ—¥åˆ¥ä¿æœ‰éŠ˜æŸ„ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ç”Ÿæˆä¸­...")
        progress_heatmap = st.progress(0)
        heatmap_log = st.empty()

        start_time = time.time()

        # UIã‚’å³åæ˜ ã•ã›ã‚‹ãŸã‚ã®çŸ­ã„é…å»¶
        time.sleep(0.1)

        # ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ç”Ÿæˆã®ãŸã‚ã«ã€results_df ã‚’æ—¥ä»˜å˜ä½ã§å‡¦ç†
        unique_dates = sorted(results_df["entry_date"].dt.normalize().unique())
        total_dates = len(unique_dates)

        for i, date in enumerate(unique_dates, 1):
            # 1æ—¥åˆ†ã®ä¿æœ‰çŠ¶æ³è¨ˆç®—
            sub_df = results_df[
                (results_df["entry_date"] <= date) & (results_df["exit_date"] >= date)
            ]
            # é€²æ—ãƒãƒ¼æ›´æ–°
            progress_heatmap.progress(i / total_dates)
            # çµŒéæ™‚é–“ã¨æ®‹ã‚Šæ™‚é–“ã®è¨ˆç®—
            elapsed = time.time() - start_time
            remain = elapsed / i * (total_dates - i)

            # ãƒ­ã‚°è¡¨ç¤ºï¼ˆ10æ—¥ã”ã¨ or æœ€çµ‚æ—¥ï¼‰
            if i % 10 == 0 or i == total_dates:
                heatmap_log.text(
                    f"ğŸ“Š æ—¥åˆ¥ä¿æœ‰éŠ˜æŸ„ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—: {i}/{total_dates} æ—¥å‡¦ç†å®Œäº†"
                    f" | çµŒé: {int(elapsed // 60)}åˆ†{int(elapsed % 60)}ç§’ "
                    f"/ æ®‹ã‚Š: ç´„ {int(remain // 60)}åˆ†{int(remain % 60)}ç§’"
                )
            time.sleep(0.01)  # è¡¨ç¤ºã®ãŸã‚ã®å°ã•ãªé…å»¶

        # å®Œäº†å¾Œã«ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸åˆ‡ã‚Šæ›¿ãˆ
        heatmap_log.text("âœ… æ—¥åˆ¥ä¿æœ‰éŠ˜æŸ„ãƒ‡ãƒ¼ã‚¿å‡¦ç†å®Œäº†ã€‚å›³ã‚’ç”Ÿæˆä¸­...")
        time.sleep(1.0)  # å°‘ã—å¾…æ©Ÿã—ã¦ã‹ã‚‰ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ç”Ÿæˆ
        heatmap_log.text("ğŸ“Š ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—æç”»ä¸­...")

        # --- ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ç”Ÿæˆã¨è¡¨ç¤º ---
        holding_matrix = generate_holding_matrix(results_df)
        display_holding_heatmap(
            holding_matrix, title=f"{system_name}ï¼šæ—¥åˆ¥ä¿æœ‰éŠ˜æŸ„ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—"
        )
        download_holding_csv(
            holding_matrix, filename=f"holding_status_{system_name}.csv"
        )

        progress_heatmap.empty()
        heatmap_log.success("ğŸ“Š ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ç”Ÿæˆå®Œäº†")

        # --- ä¿å­˜å‡¦ç† ---
        today_str = pd.Timestamp.today().date().isoformat()
        save_dir = "results_csv"
        os.makedirs(save_dir, exist_ok=True)

        # æˆ»ã‚Šå€¤ã¨ã—ã¦è¿”ã™
        if system_name in [
            "System1",
            "System2",
            "System3",
            "System4",
            "System5",
            "System6",
        ]:
            return results_df, merged_df, prepared_dict
        else:
            return results_df, None, prepared_dict

    return None, None, None


# ============================================================
# Signalä»¶æ•° + Tradeä»¶æ•° å…±é€šè¡¨ç¤º
# ============================================================
def show_signal_trade_summary(
    signal_counts_df: pd.DataFrame,
    trades_df: pd.DataFrame,
    system_name: str = "SystemX",
) -> pd.DataFrame:
    """
    éŠ˜æŸ„åˆ¥ Signal_Count + Trade_Count ã‚’é›†è¨ˆã—è¡¨ç¤ºã™ã‚‹å…±é€šUI
    - signal_counts_df: DataFrame(columns=["symbol", "Signal_Count"])
    - trades_df: ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆçµæœ DataFrame
    - system_name: è¡¨ç¤ºç”¨ã®ã‚·ã‚¹ãƒ†ãƒ å
    """
    # Trade_Count é›†è¨ˆ
    if not trades_df.empty:
        trade_counts = (
            trades_df.groupby("symbol").size().reset_index(name="Trade_Count")
        )
    else:
        trade_counts = pd.DataFrame(columns=["symbol", "Trade_Count"])

    # ãƒãƒ¼ã‚¸
    summary_df = pd.merge(
        signal_counts_df, trade_counts, on="symbol", how="outer"
    ).fillna(0)
    summary_df["Signal_Count"] = summary_df["Signal_Count"].astype(int)
    summary_df["Trade_Count"] = summary_df["Trade_Count"].astype(int)

    # è¡¨ç¤º
    with st.expander(
        f"ğŸ“Š {system_name} éŠ˜æŸ„åˆ¥ã‚·ã‚°ãƒŠãƒ«ç™ºç”Ÿä»¶æ•°ã¨ãƒˆãƒ¬ãƒ¼ãƒ‰ä»¶æ•°ï¼ˆå…¨æœŸé–“ï¼‰",
        expanded=False,
    ):
        st.dataframe(summary_df.sort_values("Signal_Count", ascending=False))

    return summary_df


# ============================================================
# Signalä»¶æ•°ãƒ»Tradeãƒ­ã‚°ãƒ»åŠ å·¥æ¸ˆãƒ‡ãƒ¼ã‚¿ä¿å­˜ å…±é€šé–¢æ•°
# ============================================================
def save_signal_and_trade_logs(signal_counts_df, results_df, system_name, capital):
    """Signalä»¶æ•°ã¨Tradeãƒ­ã‚°ã‚’CSVä¿å­˜"""
    today_str = pd.Timestamp.today().date().isoformat()
    save_dir = "results_csv"
    os.makedirs(save_dir, exist_ok=True)

    # Signalä»¶æ•°
    signal_path = os.path.join(
        save_dir,
        "signals",
        f"{system_name.lower()}_signals_{today_str}_{int(capital)}.csv",
    )
    os.makedirs(os.path.dirname(signal_path), exist_ok=True)
    signal_counts_df.to_csv(signal_path, index=False)
    st.write(f"âœ… signalä»¶æ•°ã‚‚ä¿å­˜æ¸ˆã¿: {signal_path}")

    # Tradeãƒ­ã‚°
    trade_path = os.path.join(
        save_dir, f"{system_name.lower()}_{today_str}_{int(capital)}.csv"
    )
    results_df.to_csv(trade_path, index=False)
    st.write(f"ğŸ“‚ å£²è²·ãƒ­ã‚°ã‚’è‡ªå‹•ä¿å­˜: {trade_path}")


def save_prepared_data_cache(data_dict, system_name="SystemX"):
    """åŠ å·¥æ¸ˆã¿æ—¥è¶³ãƒ‡ãƒ¼ã‚¿ã‚­ãƒ£ãƒƒã‚·ãƒ¥ä¿å­˜"""
    st.info(f"ğŸ’¾ {system_name} åŠ å·¥æ¸ˆæ—¥è¶³ãƒ‡ãƒ¼ã‚¿ã‚­ãƒ£ãƒƒã‚·ãƒ¥ä¿å­˜é–‹å§‹...")
    if not data_dict:
        st.warning("âš ï¸ ä¿å­˜å¯¾è±¡ã®ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
        return

    total = len(data_dict)
    progress_bar = st.progress(0)
    for i, (sym, df) in enumerate(data_dict.items(), 1):
        path = os.path.join("data_cache", f"{safe_filename(sym)}.csv")
        df.to_csv(path)
        progress_bar.progress(i / total)

    st.write(f"ğŸ’¾ åŠ å·¥æ¸ˆæ—¥è¶³ãƒ‡ãƒ¼ã‚¿ã‚­ãƒ£ãƒƒã‚·ãƒ¥ä¿å­˜å®Œäº† ({total} ä»¶)")
    progress_bar.empty()

    st.success("ğŸ”š ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆçµ‚äº†")
