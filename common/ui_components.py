# ============================================================
# 1. ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
# ============================================================
import os
import time
import streamlit as st
import matplotlib.pyplot as plt
from concurrent.futures import ThreadPoolExecutor, as_completed
import pandas as pd
from common.utils import safe_filename, get_cached_data
from holding_tracker import (
    generate_holding_matrix,
    display_holding_heatmap,
    download_holding_csv,
)
from tickers_loader import get_all_tickers
import matplotlib.ticker as mticker
from system.core import generate_roc200_ranking_system1


# ============================================================
# 2. ãƒ˜ãƒ«ãƒ‘ãƒ¼ç³»ï¼ˆå…±é€šãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ï¼‰
# ============================================================
# - clean_date_column
def clean_date_column(df: pd.DataFrame, col_name="Date") -> pd.DataFrame:
    """æ—¥ä»˜ã‚«ãƒ©ãƒ ã‚’datetimeå‹ã«å¤‰æ›ã—ã€NaTã‚’é™¤å»"""
    if col_name in df.columns:
        df = df.copy()
        df[col_name] = pd.to_datetime(df[col_name], errors="coerce")
        df = df.dropna(subset=[col_name])
    return df


# - log_with_progress
# ============================================================
# å…±é€šé€²æ—ãƒ­ã‚°é–¢æ•°ï¼ˆSystem1 å½¢å¼ï¼‰
# ============================================================
def log_with_progress(
    i,
    total,
    start_time,
    prefix="å‡¦ç†",
    batch=50,
    log_area=None,
    progress_bar=None,
    extra_msg=None,
    unit="ä»¶",
):
    """é€²æ—ãƒ­ã‚°ï¼‹é€²æ—ãƒãƒ¼ã‚’è¡¨ç¤º"""
    if i % batch == 0 or i == total:
        elapsed = time.time() - start_time
        remain = (elapsed / i) * (total - i) if i > 0 else 0
        msg = (
            f"{prefix}: {i}/{total} {unit} å®Œäº† "
            f"| çµŒé: {int(elapsed // 60)}åˆ†{int(elapsed % 60)}ç§’ "
            f"/ æ®‹ã‚Š: ç´„ {int(remain // 60)}åˆ†{int(remain % 60)}ç§’"
        )
        if extra_msg:
            msg += f"\n{extra_msg}"
        if log_area:
            log_area.text(msg)
        if progress_bar:
            progress_bar.progress(i / total)


# - default_log_callback
def default_log_callback(processed, total, start_time, prefix="ğŸ“Š"):
    import time

    elapsed = time.time() - start_time
    remain = (elapsed / processed) * (total - processed)
    return (
        f"{prefix}: {processed}/{total} ä»¶ å®Œäº†"
        f" | çµŒé: {int(elapsed//60)}åˆ†{int(elapsed%60)}ç§’"
        f" / æ®‹ã‚Š: ç´„ {int(remain//60)}åˆ†{int(remain%60)}ç§’"
    )


# ============================================================
# 3. ãƒ‡ãƒ¼ã‚¿å–å¾—å‡¦ç†
# ============================================================
# - load_symbol
def load_symbol(symbol, cache_dir="data_cache"):
    path = os.path.join(cache_dir, f"{safe_filename(symbol)}.csv")
    if not os.path.exists(path):
        return symbol, None
    return symbol, get_cached_data(symbol)


# - fetch_data
def fetch_data(symbols, max_workers=8):
    data_dict = {}
    total = len(symbols)
    st.info(f"ğŸ“„ ãƒ‡ãƒ¼ã‚¿å–å¾—é–‹å§‹ | {total} éŠ˜æŸ„ã‚’å‡¦ç†ä¸­...")
    progress_bar = st.progress(0)
    log_area = st.empty()
    buffer, start_time = [], time.time()

    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        futures = {executor.submit(load_symbol, sym): sym for sym in symbols}
        for i, future in enumerate(as_completed(futures), 1):
            sym, df = future.result()
            if df is not None and not df.empty:
                data_dict[sym] = df
                buffer.append(sym)

            # --- System1å½¢å¼ã®é€²æ—ãƒ­ã‚° ---
            if i % 50 == 0 or i == total:
                log_with_progress(
                    i,
                    total,
                    start_time,
                    prefix="ğŸ“„ ãƒ‡ãƒ¼ã‚¿å–å¾—",
                    batch=50,
                    log_area=log_area,
                    progress_bar=progress_bar,
                    extra_msg=f"éŠ˜æŸ„: {', '.join(buffer)}" if buffer else None,
                )
                buffer.clear()

    progress_bar.empty()
    return data_dict


# ============================================================
# 4. ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆé–¢é€£ï¼ˆãƒ­ã‚¸ãƒƒã‚¯å®Ÿè¡Œï¼‰
# ============================================================
# - prepare_backtest_data
def prepare_backtest_data(
    strategy, symbols, system_name="SystemX", spy_df=None, **kwargs
):
    """
    ãƒ‡ãƒ¼ã‚¿å–å¾— + ã‚¤ãƒ³ã‚¸ã‚±ãƒ¼ã‚¿ãƒ¼è¨ˆç®— + å€™è£œç”Ÿæˆ ã‚’å…±é€šå‡¦ç†åŒ–
    æˆ»ã‚Šå€¤: (prepared_dict, candidates_by_date, merged_df)
    """
    # --- ãƒ‡ãƒ¼ã‚¿å–å¾— ---
    data_dict = fetch_data(symbols)
    if not data_dict:
        st.error("æœ‰åŠ¹ãªãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
        return None, None, None

    # --- ã‚¤ãƒ³ã‚¸ã‚±ãƒ¼ã‚¿ãƒ¼è¨ˆç®— ---#
    st.info("ğŸ“Š ã‚¤ãƒ³ã‚¸ã‚±ãƒ¼ã‚¿ãƒ¼è¨ˆç®—ä¸­...")
    ind_progress = st.progress(0)
    ind_log = st.empty()
    ind_buffer = []
    start_time = time.time()

    prepared_dict = strategy.prepare_data(
        data_dict,
        progress_callback=lambda done, total: ind_progress.progress(done / total),
        log_callback=lambda msg: ind_log.text(msg),  # âœ… å¼•æ•°ã¯ msg 1ã¤
        **kwargs,
    )
    ind_progress.empty()

    # --- å€™è£œç”Ÿæˆ ---
    st.info("ğŸ“Š ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—æŠ½å‡ºä¸­...")
    cand_log = st.empty()
    start_time = time.time()

    if system_name in ["System1", "System4"]:
        if spy_df is None or spy_df.empty:
            st.error(f"{system_name}: SPYãƒ‡ãƒ¼ã‚¿ãŒå¿…è¦ã§ã™ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")
            return prepared_dict, None, None

        if system_name == "System1":
            # --- ROC200ãƒ©ãƒ³ã‚­ãƒ³ã‚°ç”Ÿæˆï¼ˆæ—¥åˆ¥ / å†…éƒ¨ã§SPYãƒ•ã‚£ãƒ«ã‚¿ãƒ¼æ¸ˆã¿ï¼‰ ---#
            st.info("SYSTEM1: ğŸ“Š ROC200ãƒ©ãƒ³ã‚­ãƒ³ã‚°ç”Ÿæˆä¸­...")
            cand_log = st.empty()
            cand_progress = st.progress(0)
            start_time = time.time()

            candidates_by_date, merged_df = generate_roc200_ranking_system1(
                prepared_dict,
                spy_df,
                on_progress=lambda i, total, start: log_with_progress(
                    i,
                    total,
                    start,
                    prefix="ğŸ“Š ROC200ãƒ©ãƒ³ã‚­ãƒ³ã‚°",
                    log_area=cand_log,
                    progress_bar=cand_progress,
                    unit="æ—¥",
                ),
                on_log=None,
            )
            cand_progress.empty()
            cand_log.text("âœ… ROC200ãƒ©ãƒ³ã‚­ãƒ³ã‚°ç”Ÿæˆå®Œäº†")

        elif system_name == "System4":
            st.info("SYSTEM4: ğŸ“Š RSI4ãƒ©ãƒ³ã‚­ãƒ³ã‚°ç”Ÿæˆä¸­...")
            cand_log = st.empty()
            cand_progress = st.progress(0)
            start_time = time.time()

            candidates_by_date = strategy.generate_candidates(
                prepared_dict,
                market_df=spy_df,  # âœ… SPYã‚’æ¸¡ã™
                progress_callback=lambda i, total, start: log_with_progress(
                    i,
                    total,
                    start,
                    prefix="ğŸ“Š RSI4ãƒ©ãƒ³ã‚­ãƒ³ã‚°",
                    log_area=cand_log,
                    progress_bar=cand_progress,
                    unit="ä»¶",
                ),
            )
            cand_progress.empty()
            cand_log.text("âœ… RSI4ãƒ©ãƒ³ã‚­ãƒ³ã‚°ç”Ÿæˆå®Œäº†")
            merged_df = None

    elif system_name == "System2":
        st.info("SYSTEM2: ğŸ“Š ADX7ãƒ©ãƒ³ã‚­ãƒ³ã‚°ç”Ÿæˆä¸­...")
        cand_log = st.empty()
        cand_progress = st.progress(0)
        start_time = time.time()

        candidates_by_date, merged_df = strategy.generate_candidates(
            prepared_dict,
            progress_callback=lambda i, total, start: log_with_progress(
                i,
                total,
                start,
                prefix="ğŸ“Š ADX7ãƒ©ãƒ³ã‚­ãƒ³ã‚°",
                log_area=cand_log,
                progress_bar=cand_progress,
                unit="æ—¥",
            ),
            **kwargs,
        )
        cand_progress.empty()
        cand_log.text("âœ… ADX7ãƒ©ãƒ³ã‚­ãƒ³ã‚°ç”Ÿæˆå®Œäº†")
        merged_df = None

    elif system_name == "System7":
        cand_progress = st.progress(0)
        candidates_by_date, merged_df = (
            strategy.generate_candidates(  # â† ã‚¿ãƒ—ãƒ«ã§å—ã‘å–ã‚‹
                prepared_dict,
                progress_callback=lambda done, total, start: log_with_progress(
                    done,
                    total,
                    start,
                    prefix="ğŸ“Š å€™è£œæŠ½å‡º",
                    batch=10,
                    log_area=cand_log,
                    progress_bar=cand_progress,
                ),
                **kwargs,
            )
        )
        cand_progress.empty()
        merged_df = None  # â† System7ã¯ãƒ©ãƒ³ã‚­ãƒ³ã‚°ä¸è¦ãªã®ã§å¸¸ã«None

    else:
        # System2ã€œ6ã¯SPYã‚’ä½¿ã‚ãšé€šå¸¸é€šã‚Š
        cand_progress = st.progress(0)  # â† è¿½åŠ 
        candidates_by_date, merged_df = strategy.generate_candidates(
            prepared_dict,
            progress_callback=lambda done, total: log_with_progress(
                done,
                total,
                start_time,
                prefix="ğŸ“Š å€™è£œæŠ½å‡º",
                batch=10,
                log_area=cand_log,
                progress_bar=cand_progress,
            ),
            **kwargs,
        )
        cand_progress.empty()
        merged_df = None

    if not candidates_by_date:
        st.warning(f"{system_name}: ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—æ¡ä»¶ã‚’æº€ãŸã™éŠ˜æŸ„ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        return prepared_dict, None, None

    # ğŸ”½ å€™è£œãŒã‚ã‚‹å ´åˆã¯ã“ã¡ã‚‰ã§è¿”ã™
    return prepared_dict, candidates_by_date, merged_df


# - run_backtest_with_logging
def run_backtest_with_logging(
    strategy, prepared_dict, candidates_by_date, capital, system_name="SystemX"
):
    st.info("ğŸ’¹ ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆå®Ÿè¡Œä¸­...")
    progress = st.progress(0)
    log_area = st.empty()
    debug_area = st.empty()  # å®Ÿè¡Œä¸­ã®ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ­ã‚°ç”¨
    start_time = time.time()

    debug_logs = []  # è³‡é‡‘æ¨ç§»ãƒ­ã‚°ã‚’æºœã‚ã‚‹ãƒªã‚¹ãƒˆ

    # å…±é€šãƒ­ã‚°ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯
    def log_callback(i=None, total=None, start=None, msg=None):
        if msg is not None:
            if st.session_state.get("show_debug_logs", True):
                debug_logs.append(msg)
                debug_area.text(msg)  # æœ€æ–°çŠ¶æ…‹ã ã‘ã‚’æ›´æ–°
        elif i is not None and total is not None:
            log_with_progress(
                i,
                total,
                start,
                prefix="ğŸ’¹ ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆ",
                batch=50,
                log_area=log_area,
                progress_bar=progress,
            )

    results_df = strategy.run_backtest(
        prepared_dict,
        candidates_by_date,
        capital,
        on_progress=lambda i, total, start: log_with_progress(
            i,
            total,
            start,
            prefix="ğŸ’¹ ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆ",
            log_area=log_area,  # â† ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ç”¨ã®ãƒ­ã‚°
            progress_bar=progress,
            unit="æ—¥",
        ),
        on_log=lambda msg: (
            debug_logs.append(msg) if msg.startswith("ğŸ’°") else log_area.text(msg)
        ),
    )

    progress.empty()  # â† å®Œäº†å¾Œã«ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ã‚’æ¶ˆã™

    # --- å®Ÿè¡Œå¾Œã«expanderã§ã¾ã¨ã‚ã¦è¡¨ç¤º ---
    if st.session_state.get("show_debug_logs", True) and debug_logs:
        with st.expander("ğŸ’° è³‡é‡‘æ¨ç§»ãƒ­ã‚°ï¼ˆå…¨ä»¶è¡¨ç¤ºãƒ»æŠ˜ã‚ŠãŸãŸã¿ï¼‰", expanded=False):
            st.text("\n".join(debug_logs))

    return results_df


# ============================================================
# 5. UIã‚¢ãƒ—ãƒªæœ¬ä½“
# ============================================================
# - run_backtest_app
def run_backtest_app(
    strategy,
    system_name="SystemX",
    limit_symbols=10,
    system_title=None,
    spy_df=None,
    **kwargs,
):

    st.title(system_title or f"{system_name} ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆ")

    if st.button("âš ï¸ Streamlitã‚­ãƒ£ãƒƒã‚·ãƒ¥å…¨ã‚¯ãƒªã‚¢"):
        st.cache_data.clear()
        st.success("Streamlit cache cleared.")

    # --- è©³ç´°ãƒ­ã‚°è¡¨ç¤ºåˆ‡ã‚Šæ›¿ãˆ ---
    if "show_debug_logs" not in st.session_state:
        st.session_state["show_debug_logs"] = True

    st.checkbox("è©³ç´°ãƒ­ã‚°ã‚’è¡¨ç¤º", key="show_debug_logs")

    use_auto = st.checkbox("è‡ªå‹•ãƒ†ã‚£ãƒƒã‚«ãƒ¼å–å¾—ï¼ˆå…¨éŠ˜æŸ„ï¼‰", value=True)
    capital = st.number_input("ç·è³‡é‡‘ï¼ˆUSDï¼‰", min_value=1000, value=1000, step=100)

    all_tickers = get_all_tickers()
    max_allowed = len(all_tickers)
    default_value = min(10, max_allowed)

    if system_name != "System7":
        # ğŸ”½ å–å¾—éŠ˜æŸ„æ•°æŒ‡å®šUI
        limit_symbols = st.number_input(
            "å–å¾—éŠ˜æŸ„æ•°ï¼ˆä¸Šé™ï¼‰",
            min_value=10,
            max_value=max_allowed,
            value=default_value,
            step=100,
            key=f"{system_name}_limit",
        )

        # ğŸ”½ å…¨éŠ˜æŸ„ã‚’å¯¾è±¡ã«ã™ã‚‹ã‚ªãƒ—ã‚·ãƒ§ãƒ³
        if st.checkbox("å…¨éŠ˜æŸ„ã‚’å¯¾è±¡ã«å®Ÿæ–½", key=f"{system_name}_all"):
            limit_symbols = max_allowed

    symbols_input = None
    if not use_auto:
        symbols_input = st.text_input(
            "ãƒ†ã‚£ãƒƒã‚«ãƒ¼ã‚’ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šã§å…¥åŠ›",
            "AAPL,MSFT,TSLA,NVDA,META",
            key=f"{system_name}_symbols_main",
        )

    if system_name == "System7":
        # ğŸ”½ System7ã¯SPYå°‚ç”¨
        symbols = ["SPY"]

    elif use_auto:
        symbols = all_tickers[:limit_symbols]

    else:
        if not symbols_input:
            st.error("éŠ˜æŸ„ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
            return None, None, None, None, None
        symbols = [s.strip().upper() for s in symbols_input.split(",")]

    # --- å®Ÿè¡Œãƒœã‚¿ãƒ³ ---#
    if st.button("ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ", key=f"{system_name}_run"):

        prepared_dict, candidates_by_date, merged_df = prepare_backtest_data(
            strategy,
            symbols,
            system_name=system_name,
            spy_df=spy_df,
            **kwargs,
        )
        if candidates_by_date is None:
            return None, None, None, None, None

        # --- ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆå®Ÿè¡Œï¼ˆå…±é€šåŒ–ï¼‰ ---#
        results_df = run_backtest_with_logging(
            strategy, prepared_dict, candidates_by_date, capital, system_name
        )
        show_results(results_df, capital, system_name)

        # --- æˆ»ã‚Šå€¤ã‚’ã‚·ã‚¹ãƒ†ãƒ ã”ã¨ã«åˆ‡ã‚Šæ›¿ãˆ ---#
        if system_name == "System1":
            return results_df, merged_df, prepared_dict, capital, candidates_by_date
        else:
            return results_df, None, prepared_dict, capital, candidates_by_date

    # âš ï¸ å®Ÿè¡Œãƒœã‚¿ãƒ³ãŒæŠ¼ã•ã‚Œãªã‹ã£ãŸå ´åˆã‚‚å¿…ãš5è¦ç´ è¿”ã™
    return None, None, None, None, None


# ============================================================
# 6. UIè¡¨ç¤ºç”¨é–¢æ•°
# ============================================================
# - show_results
def show_results(results_df, capital, system_name="SystemX"):
    """
    çµæœè¡¨ç¤ºå…±é€šåŒ–:
    - ã‚µãƒãƒªãƒ¼
    - ã‚°ãƒ©ãƒ•
    - å¹´æ¬¡ãƒ»æœˆæ¬¡ã‚µãƒãƒªãƒ¼
    - ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—
    - ä¿å­˜
    """
    if results_df.empty:
        st.info("ãƒˆãƒ¬ãƒ¼ãƒ‰ã¯ç™ºç”Ÿã—ã¾ã›ã‚“ã§ã—ãŸã€‚")
        return

    st.success("âœ… ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆå®Œäº†")

    # --- çµæœè¡¨ç¤º ---#
    st.subheader("ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆçµæœ")
    st.dataframe(results_df)

    summary, results_df = summarize_results(results_df, capital)
    col1, col2, col3, col4 = st.columns(4)
    col1.metric("ãƒˆãƒ¬ãƒ¼ãƒ‰å›æ•°", summary["trades"])
    col2.metric("æœ€çµ‚æç›Š (USD)", f"{summary['total_return']:.2f}")
    col3.metric("å‹ç‡ (%)", f"{summary['win_rate']:.2f}")
    col4.metric("æœ€å¤§ãƒ‰ãƒ­ãƒ¼ãƒ€ã‚¦ãƒ³ (USD)", f"{summary['max_dd']:.2f}")

    # --- æç›Šã‚°ãƒ©ãƒ• ---#
    st.subheader("ğŸ“ˆ ç´¯ç©æç›Š")
    plt.figure(figsize=(10, 4))
    plt.plot(
        results_df["exit_date"],
        results_df["cumulative_pnl"],
        label="Cumulative PnL",
    )
    plt.xlabel("æ—¥ä»˜")
    plt.ylabel("æç›Š (USD)")
    plt.title("ç´¯ç©æç›Š")
    plt.legend()
    st.pyplot(plt)

    # --- ã‚µãƒãƒªãƒ¼ ---#
    st.subheader("ğŸ“… å¹´æ¬¡ã‚µãƒãƒªãƒ¼")
    st.dataframe(
        results_df.groupby(results_df["exit_date"].dt.to_period("Y"))["pnl"]
        .sum()
        .reset_index()
    )

    st.subheader("ğŸ“† æœˆæ¬¡ã‚µãƒãƒªãƒ¼")
    st.dataframe(
        results_df.groupby(results_df["exit_date"].dt.to_period("M"))["pnl"]
        .sum()
        .reset_index()
    )

    # --- æ—¥åˆ¥ä¿æœ‰éŠ˜æŸ„ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ— ---
    st.subheader("ğŸ“Š æ—¥åˆ¥ä¿æœ‰éŠ˜æŸ„ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—")
    st.info("ğŸ“Š æ—¥åˆ¥ä¿æœ‰éŠ˜æŸ„ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ç”Ÿæˆä¸­...")
    progress_heatmap = st.progress(0)
    heatmap_log = st.empty()
    start_time = time.time()

    unique_dates = sorted(results_df["entry_date"].dt.normalize().unique())
    total_dates = len(unique_dates)

    for i, date in enumerate(unique_dates, 1):
        _ = results_df[
            (results_df["entry_date"] <= date) & (results_df["exit_date"] >= date)
        ]
        log_with_progress(
            i,
            total_dates,
            start_time,
            prefix="ğŸ“Š æ—¥åˆ¥ä¿æœ‰éŠ˜æŸ„ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—",
            batch=10,
            log_area=heatmap_log,
            progress_bar=progress_heatmap,
            unit="æ—¥",
        )
        time.sleep(0.01)

    # å®Œäº†å¾Œã«ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸åˆ‡ã‚Šæ›¿ãˆ
    heatmap_log.text("âœ… æ—¥åˆ¥ä¿æœ‰éŠ˜æŸ„ãƒ‡ãƒ¼ã‚¿å‡¦ç†å®Œäº†ã€‚å›³ã‚’ç”Ÿæˆä¸­...")
    time.sleep(1.0)  # å°‘ã—å¾…æ©Ÿã—ã¦ã‹ã‚‰ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ç”Ÿæˆ
    heatmap_log.text("ğŸ“Š ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—æç”»ä¸­...")

    # --- ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ç”Ÿæˆã¨è¡¨ç¤º ---#
    holding_matrix = generate_holding_matrix(results_df)
    display_holding_heatmap(
        holding_matrix, title=f"{system_name}ï¼šæ—¥åˆ¥ä¿æœ‰éŠ˜æŸ„ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—"
    )
    download_holding_csv(holding_matrix, filename=f"holding_status_{system_name}.csv")

    progress_heatmap.empty()
    heatmap_log.success("ğŸ“Š ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ç”Ÿæˆå®Œäº†")


# - show_signal_trade_summary
def show_signal_trade_summary(source_df, trades_df, system_name: str):
    """
    éŠ˜æŸ„åˆ¥ Signal ä»¶æ•°ã¨ Trade ä»¶æ•°ã‚’è¡¨ç¤ºã—ã€DataFrameã‚’è¿”ã™
    - System1: source_df = merged_df ã‚’æ¸¡ã™
    - ä»–System: source_df = prepared_dict ã‚’æ¸¡ã™
    """
    import pandas as pd

    # --- Signal_Count é›†è¨ˆ ---
    if system_name == "System1":
        signal_counts = source_df["symbol"].value_counts().reset_index()
        signal_counts.columns = ["symbol", "Signal_Count"]
    else:
        signal_counts = {
            sym: int(df["setup"].sum())
            for sym, df in source_df.items()
            if "setup" in df.columns
        }
        signal_counts = pd.DataFrame(
            signal_counts.items(), columns=["symbol", "Signal_Count"]
        )

    # --- Trade_Count é›†è¨ˆ ---
    if trades_df is not None and not trades_df.empty:
        trade_counts = (
            trades_df.groupby("symbol").size().reset_index(name="Trade_Count")
        )
    else:
        trade_counts = pd.DataFrame(columns=["symbol", "Trade_Count"])

    # --- ãƒãƒ¼ã‚¸ ---
    summary_df = pd.merge(signal_counts, trade_counts, on="symbol", how="outer").fillna(
        0
    )
    summary_df["Signal_Count"] = summary_df["Signal_Count"].astype(int)
    summary_df["Trade_Count"] = summary_df["Trade_Count"].astype(int)

    # --- è¡¨ç¤º ---
    with st.expander(
        f"ğŸ“Š {system_name} éŠ˜æŸ„åˆ¥ã‚·ã‚°ãƒŠãƒ«ç™ºç”Ÿä»¶æ•°ã¨ãƒˆãƒ¬ãƒ¼ãƒ‰ä»¶æ•°ï¼ˆå…¨æœŸé–“ï¼‰",
        expanded=False,
    ):
        st.dataframe(summary_df.sort_values("Signal_Count", ascending=False))

    return summary_df


# - display_roc200_ranking
def display_roc200_ranking(
    ranking_df, years=5, top_n=10, title="ğŸ“Š System1 æ—¥åˆ¥ROC200ãƒ©ãƒ³ã‚­ãƒ³ã‚°"
):
    """
    ROC200ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã‚’è¡¨ç¤ºã™ã‚‹UIå°‚ç”¨é–¢æ•°ã€‚
    - ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆã«ã¯å…¨æœŸé–“ã® ranking_df ã‚’æ¸¡ã™
    - è¡¨ç¤ºã§ã¯ç›´è¿‘ years å¹´ / ä¸Šä½ top_n éŠ˜æŸ„ã«çµã‚‹
    - ROC200_Rank ãŒç„¡ã‘ã‚Œã°è‡ªå‹•ã§ä»˜ä¸ã™ã‚‹
    """
    if ranking_df is None or ranking_df.empty:
        st.warning("ROC200ãƒ©ãƒ³ã‚­ãƒ³ã‚°ãŒç©ºã§ã™ã€‚")
        return

    df = ranking_df.copy()

    # --- å¿…è¦ãªã‚‰ ROC200_Rank ã‚’ä»˜ä¸ ---
    if "ROC200_Rank" not in df.columns and "ROC200" in df.columns:
        df["ROC200_Rank"] = df.groupby("Date")["ROC200"].rank(
            ascending=False, method="first"
        )

    # --- è¡¨ç¤ºç”¨ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚° ---
    if years:
        start_date = pd.Timestamp.now() - pd.DateOffset(years=years)
        df = df[df["Date"] >= start_date]
    if top_n:
        df = df.groupby("Date").head(top_n)

    # ğŸ”½ æ—¥ä»˜æ˜‡é †ï¼‹ãƒ©ãƒ³ã‚­ãƒ³ã‚°æ˜‡é †ã«ã‚½ãƒ¼ãƒˆ
    df = df.sort_values(["Date", "ROC200_Rank"], ascending=[True, True])

    with st.expander(f"{title}ï¼ˆç›´è¿‘{years}å¹´ / ä¸Šä½{top_n}éŠ˜æŸ„ï¼‰", expanded=False):
        st.dataframe(
            df.reset_index(drop=True)[["Date", "ROC200_Rank", "symbol"]],
            column_config={
                "Date": st.column_config.DatetimeColumn(format="YYYY-MM-DD"),
                "ROC200_Rank": st.column_config.NumberColumn(width="small"),
                "symbol": st.column_config.TextColumn(width="small"),
            },
            hide_index=False,
        )


# - summarize_results
def summarize_results(results_df, capital):
    """
    ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆçµæœã‹ã‚‰å…±é€šã‚µãƒãƒªãƒ¼ã‚’è¿”ã—ã¤ã¤ã€
    results_df ã« cumulative_pnl / drawdown ã‚‚è¿½åŠ ã—ã¦è¿”ã™
    """
    if results_df.empty:
        return {}, results_df

    results_df = results_df.copy()
    results_df["exit_date"] = pd.to_datetime(results_df["exit_date"])
    results_df = results_df.sort_values("exit_date")

    # ç´¯ç©PnLã¨ãƒ‰ãƒ­ãƒ¼ãƒ€ã‚¦ãƒ³ã‚’è¿½åŠ 
    results_df["cumulative_pnl"] = results_df["pnl"].cumsum()
    results_df["cum_max"] = results_df["cumulative_pnl"].cummax()
    results_df["drawdown"] = results_df["cumulative_pnl"] - results_df["cum_max"]

    total_return = results_df["pnl"].sum()
    win_rate = (results_df["return_%"] > 0).mean() * 100
    max_dd = results_df["drawdown"].min()

    summary = {
        "trades": len(results_df),
        "total_return": total_return,
        "win_rate": win_rate,
        "max_dd": max_dd,
    }
    return summary, results_df


# ============================================================
# 7. ä¿å­˜ç³»
# ============================================================
# - save_signal_and_trade_logs
def save_signal_and_trade_logs(signal_counts_df, results, system_name, capital):
    """Signalä»¶æ•°ã¨Tradeãƒ­ã‚°ã‚’CSVä¿å­˜"""
    today_str = pd.Timestamp.today().strftime("%Y-%m-%d_%H%M")
    save_dir = "results_csv"
    os.makedirs(save_dir, exist_ok=True)

    # --- Signalä»¶æ•° ---
    sig_dir = os.path.join(save_dir, "signals")
    os.makedirs(sig_dir, exist_ok=True)
    signal_path = os.path.join(
        sig_dir, f"{system_name}_signals_{today_str}_{int(capital)}.csv"
    )
    if signal_counts_df is not None and not signal_counts_df.empty:
        signal_counts_df.to_csv(signal_path, index=False)
        st.write(f"âœ… signalä»¶æ•°ã‚‚ä¿å­˜æ¸ˆã¿: {signal_path}")

    # --- Tradeãƒ­ã‚° ---
    trade_dir = os.path.join(save_dir, "trades")
    os.makedirs(trade_dir, exist_ok=True)
    trade_path = os.path.join(
        trade_dir, f"{system_name}_trades_{today_str}_{int(capital)}.csv"
    )

    # list â†’ DataFrame å¤‰æ›
    if isinstance(results, list):
        trades_df = pd.DataFrame(results) if results else pd.DataFrame()
    else:
        trades_df = results

    if trades_df is not None and not trades_df.empty:
        trades_df.to_csv(trade_path, index=False)
        st.write(f"ğŸ“‚ å£²è²·ãƒ­ã‚°ã‚’è‡ªå‹•ä¿å­˜: {trade_path}")


# - save_prepared_data_cache
def save_prepared_data_cache(data_dict, system_name="SystemX"):
    """åŠ å·¥æ¸ˆã¿æ—¥è¶³ãƒ‡ãƒ¼ã‚¿ã‚­ãƒ£ãƒƒã‚·ãƒ¥ä¿å­˜"""
    st.info(f"ğŸ’¾ {system_name} åŠ å·¥æ¸ˆæ—¥è¶³ãƒ‡ãƒ¼ã‚¿ã‚­ãƒ£ãƒƒã‚·ãƒ¥ä¿å­˜é–‹å§‹...")
    if not data_dict:
        st.warning("âš ï¸ ä¿å­˜å¯¾è±¡ã®ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
        return

    total = len(data_dict)
    progress_bar = st.progress(0)
    for i, (sym, df) in enumerate(data_dict.items(), 1):
        path = os.path.join("data_cache", f"{safe_filename(sym)}.csv")
        df.to_csv(path)
        progress_bar.progress(i / total)

    st.write(f"ğŸ’¾ åŠ å·¥æ¸ˆæ—¥è¶³ãƒ‡ãƒ¼ã‚¿ã‚­ãƒ£ãƒƒã‚·ãƒ¥ä¿å­˜å®Œäº† ({total} ä»¶)")
    progress_bar.empty()

    st.success("ğŸ”š ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆçµ‚äº†")
# 7-x. æ—§APIã®å§”è­²Eå¾Œæ–¹äº’æ›EE# ============================================================
"""
# ============================================================
# 7-x. æ—§APIã®å§”è­²ï¼ˆå¾Œæ–¹äº’æ›ï¼‰
# ============================================================
"""
# 7-x. æ—§APIã®å§”è­²ï¼ˆå¾Œæ–¹äº’æ›ï¼‰
# ============================================================
def save_prepared_data_cache(data_dict, system_name="SystemX"):
    """åŠ å·¥æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã‚­ãƒ£ãƒƒã‚·ãƒ¥ä¿å­˜ï¼ˆå…±é€šãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ã¸å§”è­²ï¼‰"""
    from common.cache_utils import save_prepared_data_cache as _save

    return _save(data_dict, system_name)
