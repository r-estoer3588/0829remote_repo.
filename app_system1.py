import streamlit as st
import pandas as pd
import numpy as np
import requests
from io import StringIO
from ta.trend import SMAIndicator
from ta.momentum import ROCIndicator
from ta.volatility import AverageTrueRange
from tickers_loader import get_all_tickers, filter_symbols_by_system1
import os
from collections import defaultdict
import matplotlib
import matplotlib.pyplot as plt
import pandas_market_calendars as mcal
from holding_tracker import generate_holding_matrix, display_holding_heatmap, download_holding_csv
import time
from concurrent.futures import ThreadPoolExecutor, as_completed
import logging
import matplotlib.ticker as mticker
from indicators_common import add_indicators
from pathlib import Path
from datetime import time as dtime
import subprocess
from common.utils import safe_filename, clean_date_column, get_cached_data, get_manual_data
from strategies.system1_strategy import System1Strategy
import threading


# æˆ¦ç•¥ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ä½œæˆ
strategy = System1Strategy()

#è­¦å‘ŠæŠ‘åˆ¶
logging.getLogger('streamlit.runtime.scriptrunner.script_run_context').setLevel(logging.ERROR)

# å…¨ä½“ã«ãƒ¡ã‚¤ãƒªã‚ªãƒ•ã‚©ãƒ³ãƒˆã‚’è¨­å®šï¼ˆWindowsç”¨ï¼‰
matplotlib.rcParams['font.family'] = 'Meiryo'

#ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒªã‚¢
if st.button("âš ï¸ Streamlitã‚­ãƒ£ãƒƒã‚·ãƒ¥å…¨ã‚¯ãƒªã‚¢"):
    st.cache_data.clear()
    st.success("Streamlit cache cleared.")

def is_last_trading_day(latest_date, today=None):
    # NYSEã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼å–å¾—
    nyse = mcal.get_calendar('NYSE')
    if today is None:
        today = pd.Timestamp.today().normalize()

    # ä»Šé€±ã®ç›´è¿‘ã®å–¶æ¥­æ—¥ãƒªã‚¹ãƒˆã‚’ç”Ÿæˆ
    schedule = nyse.schedule(start_date=today - pd.Timedelta(days=7), end_date=today)
    valid_days = schedule.index.normalize()

    # SPYãƒ‡ãƒ¼ã‚¿ã®æœ€æ–°æ—¥ä»˜ãŒæœ‰åŠ¹ãªå–¶æ¥­æ—¥ã‹åˆ¤å®š
    return latest_date.normalize() == valid_days[-1]

def get_latest_nyse_trading_day(today=None):
    nyse = mcal.get_calendar('NYSE')
    if today is None:
        today = pd.Timestamp.today().normalize()
    # ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã¯ä»Šæ—¥+1æ—¥ã‚‚ã‚«ãƒãƒ¼ï¼ˆç±³å›½ãŒã¾ã æœˆæ›œæœã«ãªã£ã¦ã„ãªã„å ´åˆç”¨ï¼‰
    sched = nyse.schedule(start_date=today - pd.Timedelta(days=7), end_date=today + pd.Timedelta(days=1))
    valid_days = sched.index.normalize()
    # ä»Šæ—¥ã‚ˆã‚Šå‰ã®ç›´è¿‘ã®å–¶æ¥­æ—¥ï¼ˆãŸã„ã¦ã„é‡‘æ›œã‹å½“æ—¥ï¼‰
    last_trading_day = valid_days[valid_days <= today].max()
    return last_trading_day

# ä¾‹ï¼šSPYå–å¾—æ™‚
def get_spy_data_cached(folder="data_cache"):
    path = os.path.join(folder, "SPY.csv")
    if os.path.exists(path):
        try:
            df = pd.read_csv(path, parse_dates=["Date"])
            if "Date" not in df.columns:
                print("âŒ 'Date'åˆ—ãŒå­˜åœ¨ã—ã¾ã›ã‚“ã€‚")
                return None
            df.set_index("Date", inplace=True)
            df = df.sort_index()
            st.write(f"âœ… SPYã‚­ãƒ£ãƒƒã‚·ãƒ¥æœ€çµ‚æ—¥: {df.index[-1].date()}")

            # NYSEã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼
            nyse = mcal.get_calendar('NYSE')
            today = pd.Timestamp.today().normalize()
            latest_trading_day = get_latest_nyse_trading_day(today)
            st.write(f"ğŸ—“ï¸ ç›´è¿‘ã®NYSEå–¶æ¥­æ—¥: {latest_trading_day.date()}")

            prev_trading_day = nyse.schedule(
                start_date=today - pd.Timedelta(days=7),
                end_date=today
            ).index.normalize()[-2]

            # ç±³å›½æ™‚é–“ã‚’å–å¾—
            ny_time = pd.Timestamp.now(tz="America/New_York").time()

            # åˆ¤å®š: å¤ã„å ´åˆ â†’ è‡ªå‹•æ›´æ–°
            if df.index[-1].normalize() < prev_trading_day and ny_time >= dtime(18, 0):
                st.warning("âš  SPYã‚­ãƒ£ãƒƒã‚·ãƒ¥ãŒå¤ã„ãŸã‚è‡ªå‹•æ›´æ–°ã—ã¾ã™...")
                try:
                    result = subprocess.run(
                        ["python", "recover_spy_cache.py"],
                        capture_output=True,
                        text=True
                    )
                    st.text(result.stdout)
                    if result.stderr:
                        st.error(result.stderr)
                except Exception as e:
                    st.error(f"SPYè‡ªå‹•æ›´æ–°å¤±æ•—: {e}")
                    return None

                # æ›´æ–°å¾Œå†èª­ã¿è¾¼ã¿
                if os.path.exists(path):
                    df = pd.read_csv(path, parse_dates=["Date"])
                    df.set_index("Date", inplace=True)
                    df = df.sort_index()
                    st.success(f"âœ… SPYã‚­ãƒ£ãƒƒã‚·ãƒ¥æ›´æ–°å¾Œ: {df.index[-1].date()}")
                    return df
                else:
                    st.error("âŒ æ›´æ–°å¾Œã‚‚SPY.csvãŒå­˜åœ¨ã—ã¾ã›ã‚“")
                    return None

            # é€šå¸¸ã¯ç¾è¡Œãƒ‡ãƒ¼ã‚¿ã‚’è¿”ã™
            st.write("âœ… SPYã‚­ãƒ£ãƒƒã‚·ãƒ¥ã¯æœ‰åŠ¹")
            return df

        except Exception as e:
            st.error(f"âŒ SPYèª­ã¿è¾¼ã¿å¤±æ•—: {e}")
            return None
    else:
        st.error("âŒ SPY.csv ãŒå­˜åœ¨ã—ã¾ã›ã‚“")
        return None

@st.cache_data
def get_spy_with_indicators(spy_df=None):
    if spy_df is None:
        spy_df = get_spy_data_cached()
    if spy_df is not None and not spy_df.empty:
        spy_df["SMA100"] = SMAIndicator(spy_df["Close"], window=100).sma_indicator()
        spy_df["SMA200"] = SMAIndicator(spy_df["Close"], window=200).sma_indicator()
        spy_df["spy_filter"] = (spy_df["Close"] > spy_df["SMA200"]).astype(int)
    return spy_df

# ä¸¦åˆ—å‡¦ç†ã§ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
def load_symbol(symbol):
    path = os.path.join("data_cache", f"{safe_filename(symbol)}.csv")
    if not os.path.exists(path):
        return symbol, None
    df = get_cached_data(symbol)
    return symbol, df

def summarize_signals(trades_df):
    """trades_dfã‚’Symbolã¨signalã§é›†è¨ˆã—DataFrameã‚’è¿”ã™"""
    if trades_df is None or trades_df.empty:
        return pd.DataFrame(columns=["Symbol", "signal", "count"])
    return (
        trades_df.groupby(["Symbol", "signal"])
        .size()
        .reset_index(name="count")
        .sort_values(["signal", "count"], ascending=[True, False])
    )

#çµ±åˆå®Ÿæ–½ç”¨
if __name__ == "__main__":
    st.title("ã‚·ã‚¹ãƒ†ãƒ 1ï¼šãƒ­ãƒ³ã‚°ãƒ»ãƒˆãƒ¬ãƒ³ãƒ‰ãƒ»ãƒã‚¤ãƒ»ãƒ¢ãƒ¡ãƒ³ã‚¿ãƒ ï¼ˆè¤‡æ•°éŠ˜æŸ„ï¼‹ãƒ©ãƒ³ã‚­ãƒ³ã‚°ï¼‰")
    debug_mode = st.checkbox("è©³ç´°ãƒ­ã‚°ã‚’è¡¨ç¤ºï¼ˆSystem1ï¼‰", value=False, key="system1_debug")

    use_auto = st.checkbox("è‡ªå‹•ãƒ†ã‚£ãƒƒã‚«ãƒ¼å–å¾—ï¼ˆSystem1ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼é©ç”¨ï¼‰", value=True)
    capital = st.number_input("ç·è³‡é‡‘ï¼ˆUSDï¼‰", min_value=1000, value=1000, step=100)

    # ğŸ”½ ã“ã“ã‚’è¿½åŠ ï¼šæ‰‹å‹•å…¥åŠ›UIã¯ use_auto=False ã®ã¨ãã ã‘æç”»
    Symbols_input = None
    if not use_auto:
        Symbols_input = st.text_input(
            "ãƒ†ã‚£ãƒƒã‚«ãƒ¼ã‚’ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šã§å…¥åŠ›ï¼ˆä¾‹ï¼šAAPL,MSFT,METAï¼‰",
            "AAPL,MSFT,META,AMZN,GOOGL"
    )
    spy_df = None  # åˆæœŸåŒ–
    if st.button("ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ"):
        spy_df = get_spy_data_cached()
        if spy_df is None or spy_df.empty:
            st.error("SPYãƒ‡ãƒ¼ã‚¿ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸã€‚ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’æ›´æ–°ã—ã¦ãã ã•ã„ã€‚")
            st.stop()
        max_workers = 8  # èª¿æ•´å¯
        all_tickers = get_all_tickers()
        # ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆå®Ÿè¡Œãƒœã‚¿ãƒ³æŠ¼ä¸‹å¾Œã®å‡¦ç†é–‹å§‹ç›´å¾Œã«è¿½åŠ 
        st.info(f"ğŸ” run_backtest é–‹å§‹ | {len(all_tickers)} éŠ˜æŸ„ã‚’å–å¾—ã—ã¾ã—ãŸ")
        # ãƒ‡ãƒ¼ã‚¿å–å¾—ãƒ­ã‚°ã‚’å…ˆã«ä½œã‚‹ï¼ˆç”»é¢ã®ä¸Šã«è¡¨ç¤ºï¼‰
        data_log_area = st.empty()
        # æŒ‡æ¨™è¨ˆç®—ãƒ­ã‚°ã‚’ãã®ä¸‹ã«ä½œã‚‹
        ind_log_area = st.empty()

        if use_auto:
            # ğŸ”½ (0809å®Ÿè£…ç”¨)ã“ã“ã§éŠ˜æŸ„æ•°ä¸Šé™100ã«åˆ¶é™
            select_tickers = get_all_tickers()[:100]  
            data_dict = {}
            log_container = st.container()  # è¤‡æ•°è¡Œä¿æŒç”¨
            start_time = time.time()

            if spy_df is None or spy_df.empty:
                st.error("SPYãƒ‡ãƒ¼ã‚¿ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸã€‚ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’æ›´æ–°ã—ã¦ãã ã•ã„ã€‚")
                st.stop()
            spy_df["SMA200"] = SMAIndicator(spy_df["Close"], window=200).sma_indicator()
            spy_df["spy_filter"] = (spy_df["Close"] > spy_df["SMA200"]).astype(int)

            # 1. ãƒ‡ãƒ¼ã‚¿å–å¾—ãƒ•ã‚§ãƒ¼ã‚º
            # è¨­å®š
            start_time = time.time()
            raw_data_dict = {}
            total = len(select_tickers)
            batch_size = 50
            symbol_buffer = []
            # é€²æ—ãƒãƒ¼ã€é€²æ—ãƒ­ã‚°ä½œæˆ
            data_area = st.empty()
            data_area.info(f"ğŸ“„ ãƒ‡ãƒ¼ã‚¿å–å¾—é–‹å§‹ | {total} éŠ˜æŸ„ã‚’å‡¦ç†ä¸­...")

            data_progress_bar = st.progress(0)
            data_log_area = st.empty()

            with ThreadPoolExecutor(max_workers=max_workers) as executor:
                futures = {executor.submit(load_symbol, sym): sym for sym in select_tickers}
                for i, future in enumerate(as_completed(futures), 1):
                    Symbol, df = future.result()
                    if df is not None and not df.empty:
                        raw_data_dict[Symbol] = df
                        symbol_buffer.append(Symbol)

                    if i % batch_size == 0 or i == total:
                        elapsed = time.time() - start_time
                        remaining = (elapsed / i) * (total - i)
                        elapsed_min, elapsed_sec = divmod(int(elapsed), 60)
                        remain_min, remain_sec = divmod(int(remaining), 60)
                        joined_symbols = ", ".join(symbol_buffer)
                        data_log_area.text(
                            f"ğŸ“„ ãƒ‡ãƒ¼ã‚¿å–å¾—: {i}/{total} ä»¶ å®Œäº†"
                            f" | çµŒé: {elapsed_min}åˆ†{elapsed_sec}ç§’ / æ®‹ã‚Š: ç´„ {remain_min}åˆ†{remain_sec}ç§’\n"
                            f"éŠ˜æŸ„: {joined_symbols}"
                        )
                        data_progress_bar.progress(i / total)
                        symbol_buffer.clear()
            data_progress_bar.empty()  # ãƒ‡ãƒ¼ã‚¿å–å¾—ãƒ•ã‚§ãƒ¼ã‚ºçµ‚äº†

            # 2. åŠ å·¥å‡¦ç†ãƒ•ã‚§ãƒ¼ã‚ºã€€(æŒ‡æ¨™è¨ˆç®—)
            # è¨­å®š
            start_time = time.time()
            batch_size = 50    
            # é€²æ—ãƒãƒ¼ã€é€²æ—ãƒ­ã‚°ä½œæˆ
            ind_area = st.empty()
            ind_area.info(f"ğŸ“Š æŒ‡æ¨™è¨ˆç®—é–‹å§‹ | {len(raw_data_dict)} éŠ˜æŸ„ã‚’å‡¦ç†ä¸­...")
            ind_progress_bar = st.progress(0)
            ind_log_area = st.empty()
        
            data_dict = strategy.prepare_data(
                raw_data_dict,
                progress_callback=lambda done, total: ind_progress_bar.progress(done / total),
                log_callback=lambda msg: ind_log_area.text(msg),
                batch_size=batch_size
            )
            ind_progress_bar.empty()

            st.write("ğŸ“Š æŒ‡æ¨™è¨ˆç®—å®Œäº†"
                     f" | {len(data_dict)} éŠ˜æŸ„ã®ãƒ‡ãƒ¼ã‚¿ã‚’å‡¦ç†ã—ã¾ã—ãŸ")
            if not data_dict:
                st.error("æœ‰åŠ¹ãªéŠ˜æŸ„ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
                st.stop()
            
            # 3. ROC200ãƒ©ãƒ³ã‚­ãƒ³ã‚°ä½œæˆãƒ•ã‚§ãƒ¼ã‚º
            # è¨­å®š
            start_time = time.time()
            # é€²æ—ãƒãƒ¼ã€é€²æ—ãƒ­ã‚°ä½œæˆ
            roc_area = st.empty()
            roc_area.info("ğŸ“Š ROC200ãƒ©ãƒ³ã‚­ãƒ³ã‚°ç”Ÿæˆä¸­...")
            roc_progress = st.progress(0)
            roc_log = st.empty()

            # total_days ã‚’å…ˆã«è¨ˆç®—ã—ã¦åˆæœŸè¡¨ç¤º
            total_days = strategy.get_total_days(data_dict)


            roc_log.text(f"ğŸ“Š ROC200ãƒ©ãƒ³ã‚­ãƒ³ã‚°: 0/{total_days} æ—¥å‡¦ç†é–‹å§‹... | æ®‹ã‚Š: è¨ˆç®—ä¸­...")

            def progress_callback_roc(i, total, start_time):
                roc_progress.progress(i / total)

            def log_callback_roc(i, total, start_time):
                elapsed = time.time() - start_time
                remain = (elapsed / i) * (total - i)
                roc_log.text(
                    f"ğŸ“Š ROC200è¨ˆç®—: {i}/{total} éŠ˜æŸ„å‡¦ç†å®Œäº†"
                    f" | çµŒé: {int(elapsed//60)}åˆ†{int(elapsed%60)}ç§’"
                    f" / æ®‹ã‚Š: ç´„ {int(remain//60)}åˆ†{int(remain%60)}ç§’"
                )

            candidates_by_date, merged_df = strategy.generate_candidates(
                data_dict, spy_df,
                on_progress=progress_callback_roc,
                on_log=log_callback_roc
            )
            daily_df = clean_date_column(merged_df, col_name="Date")

            # ã“ã“ã§ true_signal_summary ã‚’ä½œã‚‹
            merged_df.rename(columns={"symbol": "Symbol"}, inplace=True)
            true_signal_summary = merged_df["Symbol"].value_counts().to_dict()

            roc_progress.empty()
            roc_log.empty()

            # ğŸ“Š ROC200ãƒ©ãƒ³ã‚­ãƒ³ã‚°é€²æ—ä»˜ãç”Ÿæˆ (å‡¦ç†)
            daily_df = clean_date_column(daily_df, col_name="Date")
            unique_dates = sorted(daily_df["Date"].unique())
            total_days = len(unique_dates)

            # ROC200ãƒ©ãƒ³ã‚¯åˆ—ã‚’è¿½åŠ 
            daily_df["ROC200_Rank"] = daily_df.groupby("Date")["ROC200"].rank(ascending=False, method="first")

            ranking_list = []
            for i, date in enumerate(unique_dates, start=1):
                top100 = daily_df[daily_df["Date"] == date].sort_values("ROC200", ascending=False).head(100)
                # Symbolã‚«ãƒ©ãƒ çµ±ä¸€
                if "symbol" in top100.columns:
                    top100 = top100.rename(columns={"symbol": "Symbol"})
                ranking_list.append(top100[["Date", "Symbol", "ROC200_Rank"]])

                roc_progress.progress(i / total_days)
                if i % 10 == 0 or i == total_days:
                    elapsed = time.time() - start_time
                    remain = elapsed / i * (total_days - i)
                    roc_log.text(
                        f"ğŸ“Š ROC200ãƒ©ãƒ³ã‚­ãƒ³ã‚°: {i}/{total_days} æ—¥å‡¦ç†å®Œäº†"
                        f" | çµŒé: {int(elapsed//60)}åˆ†{int(elapsed%60)}ç§’ / æ®‹ã‚Š: ç´„ {int(remain//60)}åˆ†{int(remain%60)}ç§’"
                    )
                    time.sleep(0.01) # â† è¡¨ç¤ºã®ãŸã‚ã®å°ã•ãªé…å»¶

            roc_progress.empty()
            roc200_ranking_df = pd.concat(ranking_list, ignore_index=True)

            # === ã“ã“ã‹ã‚‰5å¹´ãƒ•ã‚£ãƒ«ã‚¿ï¼†è¡¨ç¤º ===
            five_years_ago = pd.Timestamp.now() - pd.DateOffset(years=5)
            roc200_display_df = roc200_ranking_df[roc200_ranking_df["Date"] >= five_years_ago]

            with st.expander("ğŸ“Š æ—¥åˆ¥ROC200ãƒ©ãƒ³ã‚­ãƒ³ã‚°ï¼ˆç›´è¿‘5å¹´ / ä¸Šä½100éŠ˜æŸ„ï¼‰"):
                st.dataframe(
                    roc200_display_df.reset_index(drop=True)[["Date", "ROC200_Rank", "Symbol"]],
                    column_config={
                        "Date": st.column_config.DatetimeColumn(format="YYYY-MM-DD"),
                        "ROC200_Rank": st.column_config.NumberColumn(width="small"),
                        "Symbol": st.column_config.TextColumn(width="small")
                    },
                    hide_index=False
                )

            roc_progress.empty()
            roc_log.empty()


            # CSVã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
            csv = roc200_ranking_df.to_csv(index=False).encode("utf-8")
            st.download_button("å…¨æœŸé–“ãƒ‡ãƒ¼ã‚¿ã‚’CSVã§ä¿å­˜", data=csv, file_name="roc200_ranking_all.csv", mime="text/csv")

            # å›ºå®šãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¡¨ç¤º
            bt_area = st.empty()
            bt_area.info("ğŸ’¹ ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆå®Ÿè¡Œä¸­...")

            bt_progress = st.progress(0)
            bt_log_area = st.empty()

            # --- ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯å®šç¾© ---
            def progress_callback(i, total, start_time):
                bt_progress.progress(i / total)

            def log_callback(i, total, start_time):
                elapsed = time.time() - start_time
                remain = (elapsed / i) * (total - i)
                bt_log_area.text(
                    f"ğŸ’¹ ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆ: {i}/{total} æ—¥å‡¦ç†å®Œäº†"
                    f" | çµŒé: {int(elapsed//60)}åˆ†{int(elapsed%60)}ç§’"
                    f" / æ®‹ã‚Š: ç´„ {int(remain//60)}åˆ†{int(remain%60)}ç§’"
                )

            # --- ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ ---
            trades_df = strategy.run_backtest(
                data_dict,
                candidates_by_date,
                capital,
                on_progress=progress_callback,
                on_log=log_callback
            )

            # å›ºå®šãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’æ¶ˆã™
            bt_area.empty()

            # éŠ˜æŸ„åˆ¥ Signal_Count + Trade_Count è¡¨
            # Signal_Count: merged_dfã‹ã‚‰ä½œæˆ
            signal_counts = merged_df["Symbol"].value_counts().reset_index()
            signal_counts.columns = ["Symbol", "Signal_Count"]

            # Trade_Count: trades_dfã‹ã‚‰ä½œæˆ
            if "symbol" in trades_df.columns:
                trades_df = trades_df.rename(columns={"symbol": "Symbol"})
            trade_counts = trades_df.groupby("Symbol").size().reset_index(name="Trade_Count")

            # ãƒãƒ¼ã‚¸
            summary_df = pd.merge(signal_counts, trade_counts, on="Symbol", how="outer").fillna(0)
            summary_df["Signal_Count"] = summary_df["Signal_Count"].astype(int)
            summary_df["Trade_Count"] = summary_df["Trade_Count"].astype(int)

            with st.expander("ğŸ“Š éŠ˜æŸ„åˆ¥ã‚·ã‚°ãƒŠãƒ«ç™ºç”Ÿä»¶æ•°ã¨ãƒˆãƒ¬ãƒ¼ãƒ‰ä»¶æ•°ï¼ˆå…¨æœŸé–“ï¼‰", expanded=False):
                st.dataframe(summary_df.sort_values("Signal_Count", ascending=False))

        else:
            if not Symbols_input:
                st.error("éŠ˜æŸ„ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
                st.stop()
            Symbols = [s.strip().upper() for s in Symbols_input.split(",")]

            # æ‰‹å‹•å…¥åŠ›ãƒ¢ãƒ¼ãƒ‰
            data_dict = {}
            ind_progress_bar = st.progress(0)  
            ind_log_area = st.empty()
            for Symbol in Symbols:
                path = os.path.join("data_cache", f"{safe_filename(Symbol)}.csv")
                if not os.path.exists(path):
                    st.warning(f"{Symbol}: ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãªã—ï¼ˆdata_cache/{Symbol}.csvï¼‰")
                    continue
                df = get_cached_data(Symbol)
                if df is None or df.empty:
                    continue
                prepared = strategy.prepare_data(
                    {Symbol: df},
                    progress_callback=lambda done, total: ind_progress_bar.progress(done / total),
                    log_callback=lambda msg: ind_log_area.text(msg)
                )
                df = prepared[Symbol]
                if not df.empty:
                    data_dict[Symbol] = df

            ind_progress_bar.empty()

            spy_df = get_spy_data_cached()
            if spy_df is None or spy_df.empty:
                st.error("SPYãƒ‡ãƒ¼ã‚¿ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
                st.stop()
            spy_df["SMA100"] = SMAIndicator(spy_df["Close"], window=100).sma_indicator()

            if not data_dict:
                st.error("æœ‰åŠ¹ãªéŠ˜æŸ„ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
                st.stop()

        # 3. ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆãƒ•ã‚§ãƒ¼ã‚ºï¼ˆrun_backtestå†…éƒ¨ã§æ—¥ä»˜å˜ä½ã®é€²æ—ã‚’è¡¨ç¤ºï¼‰
        # å†è¡¨ç¤º
        bt_area.info("ğŸ’¹ ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆå®Ÿè¡Œä¸­...")

        bt_progress.empty()
        bt_log_area.empty()

        # å…¨éƒ¨trades_dfã«å¤‰æ›´
        # 4-2. ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆçµæœã®è¡¨ç¤º
        if trades_df.empty:
            st.warning("SPYã®æ¡ä»¶ã‚’æº€ãŸã•ãªã„ã‹ã€ä»•æ›ã‘å€™è£œãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        else:
            st.subheader("ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆçµæœ")
            st.dataframe(trades_df)

            total_return = trades_df["pnl"].sum()
            win_rate = (trades_df["return_%"] > 0).mean() * 100

            col1, col2, col3, col4 = st.columns(4)
            col1.metric("ãƒˆãƒ¬ãƒ¼ãƒ‰å›æ•°", f"{len(trades_df)}")
            col2.metric("æœ€çµ‚æç›Š (USD)", f"{total_return:,.2f}")
            col3.metric("å‹ç‡ (%)", f"{win_rate:.2f}")

            trades_df["exit_date"] = pd.to_datetime(trades_df["exit_date"])
            results = trades_df.sort_values("exit_date")
            results["cumulative_pnl"] = results["pnl"].cumsum()
            results["cum_max"] = results["cumulative_pnl"].cummax()
            results["drawdown"] = results["cumulative_pnl"] - results["cum_max"]
            max_dd = results["drawdown"].min()
            col4.metric("æœ€å¤§ãƒ‰ãƒ­ãƒ¼ãƒ€ã‚¦ãƒ³ (USD)", f"{max_dd:,.2f}")

            st.subheader("ç´¯ç©æç›Šã‚°ãƒ©ãƒ•")
            plt.figure(figsize=(10, 4))
            plt.plot(results["exit_date"], results["cumulative_pnl"], label="Cumulative PnL")

            min_pnl = results["cumulative_pnl"].min()
            max_pnl = results["cumulative_pnl"].max()
            margin = (max_pnl - min_pnl) * 0.1
            plt.ylim(min_pnl - margin, max_pnl + margin)

            ax = plt.gca()

            # å…ˆã«ç›®ç››ã‚Šé–“éš”ã‚’è¨­å®š
            ax.yaxis.set_major_locator(mticker.MultipleLocator(500))

            # æ¬¡ã«ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚’è¨­å®šï¼ˆKè¡¨è¨˜ï¼‰
            ax.yaxis.set_major_formatter(mticker.FuncFormatter(lambda x, _: f"${x*1e-3:.0f}K"))

            plt.xlabel("æ—¥ä»˜")
            plt.ylabel("æç›Š (USD)")
            plt.title("ç´¯ç©æç›Š")
            plt.legend()
            st.pyplot(plt)

            # âœ… è¿½åŠ ï¼šRå€ç‡è¨ˆç®—ï¼ˆ5ATRã‚’ãƒªã‚¹ã‚¯åŸºæº–ã¨ã™ã‚‹ï¼‰
            results["r_multiple"] = results["pnl"] / (results["shares"] * 5 * results["entry_price"] * 0.02)

            # âœ… å¹´æ¬¡ãƒ»æœˆæ¬¡ãƒ»é€±æ¬¡ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹
            yearly = results.groupby(results["exit_date"].dt.to_period("Y"))["pnl"].sum().reset_index()
            yearly["exit_date"] = yearly["exit_date"].astype(str)
            st.subheader("ğŸ“… å¹´æ¬¡ã‚µãƒãƒªãƒ¼")
            st.dataframe(yearly)

            monthly = results.groupby(results["exit_date"].dt.to_period("M"))["pnl"].sum().reset_index()
            monthly["exit_date"] = monthly["exit_date"].astype(str)
            st.subheader("ğŸ“… æœˆæ¬¡ã‚µãƒãƒªãƒ¼")
            st.dataframe(monthly)

            weekly = results.groupby(results["exit_date"].dt.to_period("W"))["pnl"].sum().reset_index()
            weekly["exit_date"] = weekly["exit_date"].astype(str)
            st.subheader("ğŸ“† é€±æ¬¡ã‚µãƒãƒªãƒ¼")
            st.dataframe(weekly)

            # ğŸ“Š Rå€ç‡ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ ï¼ˆ-5Rã€œ+20Rã«åˆ¶é™ï¼‰
            st.subheader("ğŸ“Š Rå€ç‡ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ ï¼ˆ-5Rï½+20Rï¼‰")
            r_values = results["r_multiple"].replace([np.inf, -np.inf], np.nan).dropna()
            r_values = r_values[(r_values > -5) & (r_values < 20)]

            plt.figure(figsize=(8, 4))
            plt.hist(r_values, bins=20, edgecolor='black', range=(-5, 20))
            plt.xlabel("Rå€ç‡")
            plt.ylabel("ä»¶æ•°")
            plt.title("Rå€ç‡ã®åˆ†å¸ƒ")
            st.pyplot(plt)

            # 4. ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆçµæœã®è¡¨ç¤º
            # ğŸ“Š æ—¥åˆ¥ä¿æœ‰éŠ˜æŸ„ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ç”Ÿæˆ
            st.subheader("ğŸ“Š System1ï¼šæ—¥åˆ¥ä¿æœ‰éŠ˜æŸ„ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—")
            heatmap_progress = st.progress(0)
            heatmap_status = st.empty()

            holding_matrix = generate_holding_matrix(
                results,
                progress_callback=lambda done, total: (
                    heatmap_progress.progress(done / total),
                    heatmap_status.text(
                        f"ğŸ”¥ ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ä½œæˆä¸­: {done}/{total} ä»¶å®Œäº†"
                    )
                )
            )

            heatmap_progress.empty()
            heatmap_status.text("âœ… ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ä½œæˆå®Œäº†")

            # âœ… è‡ªå‹•ä¿å­˜ç”¨ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã¨ãƒ•ã‚¡ã‚¤ãƒ«åã‚’å®šç¾©
            today_str = pd.Timestamp.today().date().isoformat()
            save_dir = "results_csv"
            os.makedirs(save_dir, exist_ok=True)
            save_file = os.path.join(save_dir, f"system1_{today_str}_{int(capital)}.csv")

            # âœ… å£²è²·ãƒ­ã‚°ã‚’è‡ªå‹•ä¿å­˜
            results.to_csv(save_file, index=False)
            st.write(f"ğŸ“‚ å£²è²·ãƒ­ã‚°ã‚’è‡ªå‹•ä¿å­˜: {save_file}")

            # âœ… signal_summaryã®è‡ªå‹•ä¿å­˜ï¼ˆå­˜åœ¨ã™ã‚‹å ´åˆï¼‰
            if true_signal_summary:
                signal_df = pd.DataFrame(sorted(true_signal_summary.items()), columns=["Symbol", "signal_count"])
                signal_dir = os.path.join(save_dir, "signals")
                os.makedirs(signal_dir, exist_ok=True)
                signal_path = os.path.join(signal_dir, f"system1_signals_{today_str}_{int(capital)}.csv")
                signal_df.to_csv(signal_path, index=False)
                st.write(f"âœ… signalä»¶æ•°ã‚‚ä¿å­˜æ¸ˆã¿: {signal_path}")

            # -------------------------------
            # åŠ å·¥æ¸ˆæ—¥è¶³ãƒ‡ãƒ¼ã‚¿ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®ä¿å­˜ï¼ˆSystem1ï¼‰
            # -------------------------------
            st.info("ğŸ’¾ System1 åŠ å·¥æ¸ˆæ—¥è¶³ãƒ‡ãƒ¼ã‚¿ã‚­ãƒ£ãƒƒã‚·ãƒ¥ä¿å­˜é–‹å§‹...")

            os.makedirs("data_cache", exist_ok=True)
            total = len(data_dict)
            progress_bar = st.progress(0)
            status_text = st.empty()

            for i, (sym, df) in enumerate(data_dict.items(), 1):
                path = os.path.join("data_cache", f"{safe_filename(sym)}.csv")
                df.to_csv(path)
                progress_bar.progress(i / total)
                status_text.text(f"ğŸ’¾ åŠ å·¥æ¸ˆæ—¥è¶³ãƒ‡ãƒ¼ã‚¿ã‚­ãƒ£ãƒƒã‚·ãƒ¥ä¿å­˜ä¸­: {i}/{total} ä»¶ å®Œäº†")

            status_text.text(f"ğŸ’¾ åŠ å·¥æ¸ˆæ—¥è¶³ãƒ‡ãƒ¼ã‚¿ã‚­ãƒ£ãƒƒã‚·ãƒ¥ä¿å­˜å®Œäº† ({total} ä»¶)")
            progress_bar.empty()
            st.success("ğŸ”š ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆçµ‚äº†")

#å˜ä½“å®Ÿæ–½
def run_tab(spy_df):
    st.header("System1ï¼šãƒ­ãƒ³ã‚°ãƒ»ãƒˆãƒ¬ãƒ³ãƒ‰ãƒ»ãƒã‚¤ãƒ»ãƒ¢ãƒ¡ãƒ³ã‚¿ãƒ ï¼ˆè¤‡æ•°éŠ˜æŸ„ï¼‹ãƒ©ãƒ³ã‚­ãƒ³ã‚°ï¼‰") 
    Symbols_input = st.text_input(
    "ãƒ†ã‚£ãƒƒã‚«ãƒ¼ã‚’ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šã§å…¥åŠ›ï¼ˆä¾‹ï¼šAAPL,MSFT,METAï¼‰",
    "AAPL,MSFT,META,AMZN,GOOGL",
    key="system1_input"
    )
    Symbols = [s.strip().upper() for s in Symbols_input.split(",")]
    capital = st.number_input("ç·è³‡é‡‘ï¼ˆUSDï¼‰", min_value=1000, value=1000, step=100, key="system1_capital")

    if st.button("ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ", key="system1_button"):
        data_dict = {}

        # ğŸ”½ è¿½åŠ ï¼šé€²æ—ãƒãƒ¼ã¨ãƒ­ã‚°é ˜åŸŸã‚’å®šç¾©
        ind_progress_bar = st.progress(0)
        ind_log_area = st.empty()

        with st.spinner("ãƒ‡ãƒ¼ã‚¿å–å¾—ä¸­..."):
            for Symbol in Symbols:
                st.write(f"â–¶ å‡¦ç†ä¸­: {Symbol}")
                df = get_manual_data(Symbol)
                if df is not None:
                    prepared = strategy.prepare_data(
                        {Symbol: df},
                        progress_callback=lambda done, total: ind_progress_bar.progress(done / total),
                        log_callback=lambda msg: ind_log_area.text(msg)
                    )
                    df = prepared[Symbol]
                    data_dict[Symbol] = df
        ind_progress_bar.empty()
        
        if spy_df is None or spy_df.empty:
            st.error("SPYãƒ‡ãƒ¼ã‚¿ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
            return

        bt_log_area = st.empty()
        bt_progress = st.progress(0)

        def progress_callback_roc(i, total, start_time):
            roc_progress.progress(i / total)

        def log_callback_roc(i, total, start_time):
            elapsed = time.time() - start_time
            remain = (elapsed / i) * (total - i)
            roc_log.text(
                f"ğŸ“Š ROC200è¨ˆç®—: {i}/{total} éŠ˜æŸ„å‡¦ç†å®Œäº†"
                f" | çµŒé: {int(elapsed//60)}åˆ†{int(elapsed%60)}ç§’"
                f" / æ®‹ã‚Š: ç´„ {int(remain//60)}åˆ†{int(remain%60)}ç§’"
            )

        candidates_by_date, merged_df = strategy.generate_candidates(
            data_dict, spy_df,
            on_progress=progress_callback_roc,
            on_log=log_callback_roc
        )

        # â‘¡ true_signal_summary ã‚’ merged_df ã‹ã‚‰ä½œæˆ
        if "symbol" in merged_df.columns:
            merged_df.rename(columns={"symbol": "Symbol"}, inplace=True)
        true_signal_summary = merged_df["Symbol"].value_counts().to_dict()

        # â‘¢ ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
        def progress_callback(i, total, start_time):
            bt_progress.progress(i / total)

        def log_callback(i, total, start_time):
            elapsed = time.time() - start_time
            remain = (elapsed / i) * (total - i)
            bt_log_area.text(
                f"ğŸ’¹ ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆ: {i}/{total} æ—¥å‡¦ç†å®Œäº†"
                f" | çµŒé: {int(elapsed//60)}åˆ†{int(elapsed%60)}ç§’"
                f" / æ®‹ã‚Š: ç´„ {int(remain//60)}åˆ†{int(remain%60)}ç§’"
            )

        trades_df = strategy.run_backtest(
            data_dict,
            candidates_by_date,
            capital,
            on_progress=progress_callback,
            on_log=log_callback
        )
        bt_progress.empty()

        # â‘£ Signal_Count + Trade_Count è¡¨
        signal_counts = pd.DataFrame(sorted(true_signal_summary.items()), columns=["Symbol", "Signal_Count"])
        if "symbol" in trades_df.columns:
            trades_df = trades_df.rename(columns={"symbol": "Symbol"})
        trade_counts = trades_df.groupby("Symbol").size().reset_index(name="Trade_Count")
        summary_df = pd.merge(signal_counts, trade_counts, on="Symbol", how="outer").fillna(0)
        summary_df["Signal_Count"] = summary_df["Signal_Count"].astype(int)
        summary_df["Trade_Count"] = summary_df["Trade_Count"].astype(int)
        st.dataframe(summary_df.sort_values("Signal_Count", ascending=False))

        # ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆçµæœè¡¨ç¤º
        if trades_df.empty:
            st.warning("ä»•æ›ã‘å€™è£œãªã—")
        else:
            st.dataframe(trades_df)

            # results ã« trades_df ã‚’ã‚»ãƒƒãƒˆ
            results = trades_df.sort_values("exit_date").copy()

            total_return = results["pnl"].sum()
            win_rate = (results["return_%"] > 0).mean() * 100
            st.metric("ãƒˆãƒ¬ãƒ¼ãƒ‰å›æ•°", len(results))
            st.metric("æœ€çµ‚æç›Šï¼ˆUSDï¼‰", f"{total_return:.2f}")
            st.metric("å‹ç‡ï¼ˆï¼…ï¼‰", f"{win_rate:.2f}")

            results["exit_date"] = pd.to_datetime(results["exit_date"])
            results = results.sort_values("exit_date")
            results["cumulative_pnl"] = results["pnl"].cumsum()
            results["cum_max"] = results["cumulative_pnl"].cummax()
            results["drawdown"] = results["cumulative_pnl"] - results["cum_max"]
            max_dd = results["drawdown"].min()
            st.metric("æœ€å¤§ãƒ‰ãƒ­ãƒ¼ãƒ€ã‚¦ãƒ³ï¼ˆUSDï¼‰", f"{max_dd:.2f}")

            st.subheader("ç´¯ç©æç›Šã‚°ãƒ©ãƒ•")
            plt.figure(figsize=(10, 4))
            plt.plot(results["exit_date"], results["cumulative_pnl"], label="Cumulative PnL")
            plt.xlabel("æ—¥ä»˜")
            plt.ylabel("æç›Š (USD)")
            plt.title("ç´¯ç©æç›Š")
            plt.legend()
            st.pyplot(plt)

            # ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆå®Ÿè¡Œå¾Œã® Streamlit ã‚»ã‚¯ã‚·ãƒ§ãƒ³å†…ã«è¿½è¨˜
            holding_matrix = generate_holding_matrix(results)
            display_holding_heatmap(holding_matrix, title="System1ï¼šæ—¥åˆ¥ä¿æœ‰éŠ˜æŸ„ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—")
            download_holding_csv(holding_matrix, filename="holding_status_system1.csv")

            csv = results.to_csv(index=False).encode("utf-8")
            st.download_button("å£²è²·ãƒ­ã‚°ã‚’CSVã§ä¿å­˜", data=csv, file_name="trade_log_system1.csv", mime="text/csv")
